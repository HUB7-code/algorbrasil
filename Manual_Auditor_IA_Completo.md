# MANUAL DO AUDITOR DE IA: Sistema de Gest√£o de Intelig√™ncia Artificial
**Baseado na ISO/IEC 42001**

---
**Autor:** Paulo Carvalho (ALGOR Association)
**Organiza√ß√£o:** ALGOR - Association for Algorithmization and Logic Governance Organization
**Contexto:** Auditoria, Governan√ßa e Compliance de IA
**Vers√£o:** 2025
---

## üìë Sum√°rio Executivo

1.  [Contexto da Organiza√ß√£o](#1-contexto-da-organiza√ß√£o)
2.  [Lideran√ßa](#2-lideran√ßa)
3.  [Planejamento](#3-planejamento)
4.  [Suporte](#4-suporte)
5.  [Opera√ß√£o](#5-opera√ß√£o)
6.  [Avalia√ß√£o de Desempenho](#6-avalia√ß√£o-de-desempenho)
7.  [Melhoria](#7-melhoria)
8.  [Controles (Anexo A)](#8-controles-anexo-a)
9.  [Regulamenta√ß√£o (EU AI Act & Brasil)](#9-regulamenta√ß√£o)

---

## üìñ Pref√°cio: O Despertar da Intelig√™ncia Viva

> [cite_start]"Vivemos um tempo liminar. Um tempo onde as estruturas conhecidas da realidade est√£o sendo silenciosamente substitu√≠das por arquiteturas invis√≠veis, feitas de dados, decis√µes automatizadas e redes de aprendizado profundo." [cite: 3270-3272]

[cite_start]A **Intelig√™ncia Viva** √© o resultado da converg√™ncia de tr√™s tecnologias de prop√≥sito geral: a pr√≥pria IA, sensores avan√ßados e bioengenharia [cite: 3275-3276]. Governan√ßa de IA n√£o √© apenas sobre tecnologia; √© a nova ci√™ncia pol√≠tica do s√©culo XXI.

Este manual oferece:
* Mapas conceituais para o ecossistema da Intelig√™ncia Viva.
* Estruturas de responsabilidade e compliance.
* Modelos de avalia√ß√£o de riscos e impactos.

---

## 1. Contexto da Organiza√ß√£o

### 1.1 Entendendo o Contexto na Pr√°tica
[cite_start]Antes de implementar qualquer sistema, a organiza√ß√£o deve responder: **"Qual √© o nosso contexto?"**[cite: 3382]. Isso envolve observar fatores internos e externos que afetam o SGIA (Sistema de Gest√£o de IA).

[cite_start]**Checklist Pr√°tico: An√°lise do Contexto** [cite: 3429-3470]

| Aspecto | Sim | Parcial | N√£o | Obs |
| :--- | :---: | :---: | :---: | :--- |
| **Diagn√≥stico Interno** | | | | |
| Temos clareza sobre nossos objetivos com IA? | [ ] | [ ] | [ ] | |
| Sabemos quem vai liderar e governar o uso da IA? | [ ] | [ ] | [ ] | |
| Existem pol√≠ticas claras sobre uso de dados? | [ ] | [ ] | [ ] | |
| A organiza√ß√£o possui equipe/parceiros com conhecimento t√©cnico? | [ ] | [ ] | [ ] | |
| **Diagn√≥stico Externo** | | | | |
| Conhecemos as leis e regula√ß√µes aplic√°veis (ex: AI Act)? | [ ] | [ ] | [ ] | |
| Entendemos as expectativas de clientes e usu√°rios? | [ ] | [ ] | [ ] | |
| Avaliamos se h√° riscos sociais, √©ticos ou ambientais? | [ ] | [ ] | [ ] | |

### 1.2 Defini√ß√£o de Pap√©is
[cite_start]√â crucial reconhecer o papel da organiza√ß√£o em rela√ß√£o √† IA [cite: 3407-3411]:
* **Fornecedor:** Entrega plataformas ou solu√ß√µes para terceiros.
* **Desenvolvedor:** Projeta, treina e testa modelos.
* **Usu√°rio:** Consome IA pronta em seus processos.
* **Parceiro/Integrador:** Compartilha dados ou integra sistemas.
* **Sujeito:** Dados pessoais s√£o processados por IA.

### 1.3 Partes Interessadas (Stakeholders)
[cite_start]A governan√ßa exige identificar quem √© afetado pela IA e suas expectativas [cite: 3497-3498]:

| Grupo | Tipo de Rela√ß√£o | Impacto Esperado |
| :--- | :--- | :--- |
| **Clientes finais** | Usu√°rios dos servi√ßos | Decis√µes automatizadas, privacidade. |
| **Colaboradores** | Operadores ou afetados | Redu√ß√£o de tarefas, requalifica√ß√£o. |
| **Reguladores** | Fiscaliza√ß√£o | Cumprimento legal e √©tico. |
| **Sociedade** | Impacto indireto | Sustentabilidade, vi√©s social. |

### 1.4 Escopo do Sistema de Gest√£o
Definir o escopo √© tra√ßar o "mapa da √°rea" que queremos cuidar.
* [cite_start]**Exemplo de Escopo:** "O SGIA se aplica ao desenvolvimento, treinamento e opera√ß√£o de modelos de linguagem generativos (ex: GPT) e sua integra√ß√£o em produtos de assist√™ncia ao cliente." [cite: 3585-3586]

---

## 2. Lideran√ßa

### 2.1 O Papel da Lideran√ßa
[cite_start]"Nenhuma iniciativa de intelig√™ncia artificial vai para frente sem o apoio genuino da lideran√ßa." [cite: 3644]

[cite_start]**7 Princ√≠pios para L√≠deres de IA** [cite: 3648-3663]:
1. **Prop√≥sito:** Definir objetivos claros alinhados √† estrat√©gia.
2. **Integra√ß√£o:** IA n√£o √© um projeto isolado, mas parte do dia a dia.
3. **Comunica√ß√£o:** Falar sobre IA respons√°vel com clareza.
4. **Apoio √† Equipe:** Incentivar inova√ß√£o e confian√ßa.
5. **Melhoria Cont√≠nua:** O sistema nunca est√° "pronto".
6. **Exemplo:** A lideran√ßa deve ser o modelo de uso √©tico.

### 2.2 Pol√≠tica de IA
[cite_start]A pol√≠tica √© a declara√ß√£o oficial da lideran√ßa sobre por que e como a IA √© usada[cite: 3681].

[cite_start]**Modelo de Estrutura de Pol√≠tica de Governan√ßa de IA** [cite: 3730-3768]:
1. **Objetivos Estrat√©gicos:** Alinhamento com valores e leis (LGPD, AI Act).
2. **Princ√≠pios √âticos:** Benef√≠cio social, n√£o discrimina√ß√£o, supervis√£o humana.
3. **Escopo:** Quais sistemas est√£o cobertos.
4. **Estrutura de Governan√ßa:** Pap√©is (Comit√™ de IA, TI, Jur√≠dico).
5. **Controles Operacionais:** Avalia√ß√£o de impacto, classifica√ß√£o de risco.
6. **Documenta√ß√£o:** Invent√°rios, logs, justificativas de uso.

> [cite_start]**Exemplo de Compromisso:** "A [Empresa] compromete-se a utilizar sistemas de IA de forma √©tica, transparente, segura e alinhada √†s legisla√ß√µes vigentes, visando gerar valor sustent√°vel." [cite: 3691]

---

## 3. Planejamento

### 3.1 Riscos e Oportunidades
Planejar bem n√£o √© prever o futuro, √© se preparar para agir.
* [cite_start]**Riscos:** Vi√©s discriminat√≥rio, alucina√ß√£o, viola√ß√£o de LGPD, falhas de seguran√ßa [cite: 3933-3936].
* [cite_start]**Oportunidades:** Efici√™ncia, redu√ß√£o de custos, novos modelos de neg√≥cio[cite: 3939].

### 3.2 Avalia√ß√£o de Impacto Algor√≠tmico (AIA)
Ferramenta essencial para projetos de alto impacto.

[cite_start]**Template Simplificado de AIA** [cite: 4261-4268]:

| Categoria | Quest√£o de Verifica√ß√£o | Avalia√ß√£o |
| :--- | :--- | :--- |
| **Direitos Fundamentais** | H√° risco de discrimina√ß√£o (g√™nero, ra√ßa, classe)? | ( ) Sim ( ) N√£o |
| **Privacidade** | Pode violar a prote√ß√£o de dados pessoais? | ( ) Sim ( ) N√£o |
| **Autonomia** | Reduz a autonomia humana em decis√µes cr√≠ticas? | ( ) Sim ( ) N√£o |
| **Vulner√°veis** | Afeta grupos vulner√°veis (crian√ßas, idosos)? | ( ) Sim ( ) N√£o |

**Decis√£o de Risco:**
* ( ) Alto
* ( ) M√©dio
* ( ) Baixo
* ( ) Inaceit√°vel

### 3.3 Objetivos de IA e OKRs
Os objetivos devem ser mensur√°veis e alinhados √† pol√≠tica.

[cite_start]**Exemplo de Planejamento com OKRs**[cite: 4357]:
* **Objetivo:** Ajudar gestores a definir metas realistas com base em dados.
* **KR 1:** Aumentar assertividade das metas em 25% usando modelo preditivo.
* **KR 2:** 90% das metas sugeridas pela IA devem ser revisadas por humanos (Supervis√£o).
* **KR 3:** Reduzir em 20% a varia√ß√£o entre o planejado e o realizado.

---

## 4. Suporte (ISO 42001)

> [cite_start]"Um bom planejamento de IA n√£o vale nada se a organiza√ß√£o n√£o tiver estrutura para execut√°-lo." [cite: 4374]

### 4.1 Recursos
A organiza√ß√£o deve disponibilizar recursos suficientes para que a IA funcione de forma segura e respons√°vel. [cite_start]Isso inclui [cite: 4402-4403]:
* **Pessoas:** Capacitadas com tempo e conhecimento.
* **Tecnologia:** Sistemas, servidores, armazenamento, redes.
* **Dados:** Prote√ß√£o e seguran√ßa digital.
* **Or√ßamento:** Para manuten√ß√£o e melhoria cont√≠nua.

### 4.2 Compet√™ncia e Conscientiza√ß√£o
N√£o adianta apenas os especialistas entenderem a IA. A norma exige:
1.  [cite_start]**Compet√™ncia:** Garantir que cada pessoa tenha o conhecimento certo para sua fun√ß√£o (treinamento, experi√™ncia) e manter registros documentados [cite: 4414-4418].
2.  [cite_start]**Conscientiza√ß√£o:** Todos (colaboradores e parceiros) devem entender [cite: 4422-4430]:
    * A pol√≠tica de IA da empresa.
    * Sua pr√≥pria contribui√ß√£o para o sistema.
    * As consequ√™ncias de n√£o seguir as regras (ex: riscos de privacidade, vi√©s).

### 4.3 Comunica√ß√£o
[cite_start]O plano de comunica√ß√£o deve responder a quatro perguntas b√°sicas [cite: 4458-4475]:

| Pergunta | Exemplo de Aplica√ß√£o |
| :--- | :--- |
| **O QUE comunicar?** | Pol√≠tica de IA, riscos, benef√≠cios, incidentes. |
| **QUANDO comunicar?** | Lan√ßamento de sistemas, atualiza√ß√µes de pol√≠tica, crises. |
| **PARA QUEM?** | Colaboradores, lideran√ßa, clientes, reguladores. |
| **COMO?** | Intranet, treinamentos, relat√≥rios p√∫blicos, reuni√µes. |

### 4.4 Informa√ß√£o Documentada
A gest√£o de IA exige provas. Os documentos devem ser controlados para garantir que estejam dispon√≠veis, atualizados e seguros.
* [cite_start]**Cria√ß√£o:** Identifica√ß√£o clara (t√≠tulo, data, autor), formato adequado e aprova√ß√£o [cite: 4516-4530].
* [cite_start]**Controle:** Distribui√ß√£o, armazenamento, controle de vers√µes e reten√ß√£o/descarte [cite: 4553-4563].

---

## 5. Opera√ß√£o

> [cite_start]"A fase operacional da IA exige disciplina, controle e vigil√¢ncia constante." [cite: 4593]

### 5.1 Planejamento e Controle Operacional
[cite_start]Antes de usar a IA, a empresa deve [cite: 4600-4620]:
1.  Definir crit√©rios de funcionamento (ex: % de acerto m√≠nimo).
2.  Aplicar controles ao longo do ciclo de vida (testes, revis√µes).
3.  Monitorar resultados e corrigir desvios.
4.  Gerenciar mudan√ßas (atualiza√ß√µes de modelo ou dados).

### 5.2 Avalia√ß√£o de Riscos de IA
[cite_start]Deve ser feita regularmente e sempre que houver mudan√ßas significativas (ex: novos dados, novo uso) [cite: 4627-4632].
* [cite_start]**O que fazer:** Identificar riscos (vieses, erros, privacidade), avaliar gravidade/probabilidade e definir tratamento [cite: 4637-4639].

### 5.3 Tratamento de Riscos
[cite_start]Decis√£o pr√°tica sobre como lidar com os riscos identificados [cite: 4655-4665]:
* **Eliminar:** Desligar ou mudar o sistema.
* **Mitigar:** Criar barreiras ou ajustes.
* **Compartilhar:** Dividir responsabilidade (seguros/parceiros).
* **Aceitar:** Se o risco for baixo e controlado.

### 5.4 Avalia√ß√£o de Impacto do Sistema de IA
[cite_start]Diferente do risco t√©cnico, aqui analisa-se o impacto em **pessoas e direitos** [cite: 4703-4705]:
* Privacidade de dados.
* Discrimina√ß√£o ou exclus√£o de grupos.
* Influ√™ncia em decis√µes humanas sens√≠veis.

---

## 6. Avalia√ß√£o de Desempenho

### 6.1 Monitoramento, Medi√ß√£o, An√°lise e Avalia√ß√£o
"Voc√™ n√£o pode melhorar o que n√£o consegue medir".
[cite_start]A empresa deve definir [cite: 4758-4771]:
* **O que medir:** Precis√£o, tempo de resposta, incidentes de vi√©s, reclama√ß√µes.
* **Como medir:** M√©todos e ferramentas.
* **Quando medir:** Diariamente? Semanalmente? Ap√≥s atualiza√ß√µes?

### 6.2 Auditoria Interna
Verifica√ß√µes peri√≥dicas para garantir conformidade com a ISO 42001 e as regras internas.
* [cite_start]**Programa de Auditoria:** Deve definir frequ√™ncia, m√©todos, escopo e garantir a imparcialidade dos auditores [cite: 4825-4841].

### 6.3 An√°lise Cr√≠tica pela Dire√ß√£o
Reuni√£o estrat√©gica onde a alta lideran√ßa revisa o sistema.
* [cite_start]**Entradas (Inputs):** Status de a√ß√µes, mudan√ßas no cen√°rio (leis/tec), feedback de stakeholders, desempenho da IA [cite: 4905-4915].
* [cite_start]**Resultados (Outputs):** Decis√µes sobre melhorias, mudan√ßas no sistema e necessidade de recursos [cite: 4928-4934].

---

## 7. Melhoria

### 7.1 N√£o Conformidade e A√ß√£o Corretiva
[cite_start]Quando algo sai errado (erro, falha, viola√ß√£o), a organiza√ß√£o deve [cite: 4978-4982]:
1.  Corrigir o problema imediatamente (conten√ß√£o).
2.  Analisar a causa raiz.
3.  Implementar a√ß√µes para evitar recorr√™ncia.
4.  Avaliar a efic√°cia da a√ß√£o.

### 7.2 Relat√≥rio de N√£o Conformidade (Modelo)
[cite_start]Estrutura essencial para registro de falhas [cite: 5008-5029]:

1.  **Identifica√ß√£o:** Data, √°rea, descri√ß√£o detalhada.
2.  **A√ß√µes Imediatas:** O que foi feito para estancar o problema.
3.  **An√°lise de Causa:** Investiga√ß√£o (Processos, Dados, Treinamento).
4.  **Avalia√ß√£o de Riscos:** Impacto e gravidade.
5.  **Plano de A√ß√£o Corretiva:** Respons√°veis e prazos.
6.  **Verifica√ß√£o de Efic√°cia:** Indicadores de sucesso.
7.  **Aprendizado:** Li√ß√µes aprendidas e refor√ßo cultural.

---

## 8. Controles (Anexo A)

Esta se√ß√£o detalha os controles de refer√™ncia da ISO/IEC 42001 para mitigar riscos e garantir os objetivos de IA.

### A.2 Pol√≠ticas Relacionadas √† IA
[cite_start]**Objetivo:** Fornecer orienta√ß√£o e suporte da gest√£o para sistemas de IA[cite: 5058].

| C√≥digo | Controle | KPIs Sugeridos |
| :--- | :--- | :--- |
| **A.2.2** | Documentar uma pol√≠tica para o desenvolvimento ou uso de sistemas de IA. | **% de Cobertura:** (√Åreas com pol√≠tica implementada / Total de √°reas) x 100 |
| **A.2.3** | Determinar como outras pol√≠ticas (seguran√ßa, privacidade) s√£o afetadas pela IA. | **Integra√ß√£o:** % de pol√≠ticas organizacionais revisadas com foco em IA. |
| **A.2.4** | Analisar criticamente a pol√≠tica em intervalos planejados para garantir efic√°cia. | **Frequ√™ncia:** N¬∫ de revis√µes realizadas vs. planejadas. |

### A.3 Organiza√ß√£o Interna
[cite_start]**Objetivo:** Estabelecer responsabiliza√ß√£o e estrutura para a gest√£o de IA[cite: 5184].

| C√≥digo | Controle | KPIs Sugeridos |
| :--- | :--- | :--- |
| **A.3.2** | Definir e alocar pap√©is e responsabilidades de IA de acordo com as necessidades. | **Defini√ß√£o de Pap√©is:** % de fun√ß√µes cr√≠ticas com respons√°veis formalmente designados. |
| **A.3.3** | Estabelecer processo para relato de preocupa√ß√µes (whistleblowing) sobre sistemas de IA. | **Canal Ativo:** Exist√™ncia de canal funcional e n¬∫ de relatos processados. |

### A.4 Recursos para Sistemas de IA
[cite_start]**Objetivo:** Garantir recursos suficientes (dados, ferramentas, humanos)[cite: 5289].

| C√≥digo | Controle | KPIs Sugeridos |
| :--- | :--- | :--- |
| **A.4.2** | Identificar e documentar recursos necess√°rios para cada est√°gio do ciclo de vida. | **Mapeamento:** % de projetos com recursos mapeados por est√°gio. |
| **A.4.3** | Documentar informa√ß√µes sobre recursos de **dados** (origem, qualidade, volume). | **Doc. de Dados:** % de projetos com documenta√ß√£o de dados validada. |
| **A.4.6** | Documentar compet√™ncias dos **recursos humanos** utilizados no ciclo de vida. | **Compet√™ncias:** % de projetos com equipe qualificada e documentada. |

### A.5 Avalia√ß√£o de Impactos
[cite_start]**Objetivo:** Avaliar consequ√™ncias para indiv√≠duos, grupos e sociedades[cite: 5439].

| C√≥digo | Controle | KPIs Sugeridos |
| :--- | :--- | :--- |
| **A.5.2** | Estabelecer processo de avalia√ß√£o de impacto (AIA) ao longo do ciclo de vida. | **Cobertura de AIA:** % de sistemas de IA com avalia√ß√£o de impacto realizada. |
| **A.5.3** | Documentar e reter os resultados das avalia√ß√µes de impacto. | **Registro:** % de avalia√ß√µes formalmente documentadas e armazenadas. |

### A.6 Ciclo de Vida do Sistema de IA
[cite_start]**Objetivo:** Definir crit√©rios e requisitos para cada est√°gio (projeto, desenvolvimento, opera√ß√£o)[cite: 5543].

| C√≥digo | Controle | KPIs Sugeridos |
| :--- | :--- | :--- |
| **A.6.1.1** | Identificar objetivos para o desenvolvimento respons√°vel de IA. | **Integra√ß√£o:** % de projetos com objetivos √©ticos/respons√°veis definidos. |
| **A.6.2.4** | Documentar plano de implanta√ß√£o e assegurar atendimento de requisitos. | **Readiness:** % de sistemas implantados com checklist de requisitos atendido. |
| **A.6.2.7** | Habilitar registro de logs de eventos (auditoria) quando o sistema estiver em uso. | **Logging:** % de sistemas operacionais com logs ativos e monitorados. |

### A.7 Dados para Sistemas de IA
[cite_start]**Objetivo:** Gerenciar a qualidade e proced√™ncia dos dados[cite: 5845].

| C√≥digo | Controle | KPIs Sugeridos |
| :--- | :--- | :--- |
| **A.7.2** | Determinar e documentar detalhes sobre aquisi√ß√£o e sele√ß√£o de dados. | **Doc. de Aquisi√ß√£o:** % de projetos com crit√©rios de sele√ß√£o de dados definidos. |
| **A.7.4** | Definir processo para verificar e registrar a proveni√™ncia (origem) dos dados. | **Rastreabilidade:** % de datasets com origem verificada. |

### A.8 Informa√ß√£o para Partes Interessadas
[cite_start]**Objetivo:** Garantir transpar√™ncia e fornecimento de informa√ß√µes[cite: 5987].

| C√≥digo | Controle | KPIs Sugeridos |
| :--- | :--- | :--- |
| **A.8.1** | Fornecer documenta√ß√£o e informa√ß√µes necess√°rias aos usu√°rios do sistema. | **Informa√ß√£o ao Usu√°rio:** % de usu√°rios com acesso √† documenta√ß√£o adequada. |
| **A.8.2** | Fornecer recursos para partes interessadas relatarem impactos adversos. | **Efetividade de Canal:** % de relatos externos respondidos no prazo. |

### A.9 Uso de Sistemas de IA
[cite_start]**Objetivo:** Assegurar o uso respons√°vel conforme pol√≠ticas[cite: 6125].

| C√≥digo | Controle | KPIs Sugeridos |
| :--- | :--- | :--- |
| **A.9.1** | Definir processos para o uso respons√°vel dos sistemas de IA. | **Ado√ß√£o:** % de processos de uso respons√°vel implementados. |
| **A.9.3** | Assegurar que o sistema seja usado conforme o "uso pretendido" documentado. | **Conformidade de Uso:** % de sistemas operando dentro do escopo definido. |

### A.10 Relacionamento com Terceiros
[cite_start]**Objetivo:** Gerenciar riscos com fornecedores, parceiros e clientes[cite: 6248].

| C√≥digo | Controle | KPIs Sugeridos |
| :--- | :--- | :--- |
| **A.10.1** | Assegurar atribui√ß√£o de responsabilidades entre organiza√ß√£o, parceiros e fornecedores. | **Responsabilidades:** % de contratos com matriz de responsabilidade de IA. |
| **A.10.2** | Assegurar que fornecedores estejam alinhados com a abordagem de IA respons√°vel. | **Alinhamento:** % de fornecedores cr√≠ticos avaliados quanto √† √©tica em IA. |

---

## 9. Regulamenta√ß√£o: EU AI Act

### Classifica√ß√£o de Risco (Pir√¢mide de Risco)
[cite_start]O regulamento europeu classifica os sistemas em 4 n√≠veis [cite: 6578-6590]:

1.  **üî¥ Risco Inaceit√°vel (Proibido):** Amea√ßa aos direitos fundamentais (ex: Social Scoring, manipula√ß√£o subliminar, reconhecimento facial em tempo real em locais p√∫blicos sem exce√ß√£o legal).
2.  **üü† Risco Elevado (Controlado):** Afetam sa√∫de, seguran√ßa ou direitos (ex: IA em recrutamento, cr√©dito, justi√ßa, infraestrutura cr√≠tica). Exigem conformidade rigorosa.
3.  **üü° Risco Limitado (Transpar√™ncia):** Intera√ß√£o com humanos (ex: Chatbots, Deepfakes). Exigem aviso claro de que √© uma IA.
4.  **üü¢ Risco M√≠nimo (Livre):** Maioria das aplica√ß√µes (ex: Filtros de spam, games). Sem restri√ß√µes adicionais.

### Requisitos para IA de Alto Risco vs. ISO 42001
[cite_start]Conex√£o entre a lei europeia e a norma t√©cnica[cite: 6821]:

| Requisito AI Act | A√ß√£o Necess√°ria | Conex√£o ISO 42001 |
| :--- | :--- | :--- |
| **Governan√ßa de Riscos** | Avalia√ß√£o cont√≠nua de riscos | A.5 Avalia√ß√£o de Impacto |
| **Qualidade dos Dados** | Dados corretos e sem vi√©s | A.7 Gest√£o de Dados |
| **Documenta√ß√£o** | Registros t√©cnicos detalhados | A.6 Ciclo de Vida |
| **Transpar√™ncia** | Usu√°rio deve entender a IA | A.8 Informa√ß√£o |
| **Supervis√£o Humana** | Humano pode intervir/desligar | A.3 Pap√©is / A.9 Uso |
| **Robustez** | Resist√™ncia a falhas/ataques | A.4 Recursos (Seguran√ßa) |

### Penalidades (Multas M√°ximas)
[cite_start]O n√£o cumprimento pode gerar multas severas[cite: 6946]:
* **35 Milh√µes ‚Ç¨ (ou 7% faturamento):** Uso de sistemas proibidos.
* **15 Milh√µes ‚Ç¨ (ou 3% faturamento):** N√£o conformidade em Alto Risco.
* **7,5 Milh√µes ‚Ç¨ (ou 1% faturamento):** Informa√ß√£o incorreta.

---
**Fim do Manual**